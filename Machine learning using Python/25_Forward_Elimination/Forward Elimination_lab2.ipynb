{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38c80fac-0f74-4ef9-975f-f7b5ca4c792a",
   "metadata": {},
   "source": [
    "## Forward Elimination: Advanced Feature Selection Techniques\n",
    "\n",
    "Forward Elimination is a stepwise feature selection technique used in statistical modeling to identify the most significant predictors for a model. Unlike backward elimination, forward elimination starts with no predictors and adds the most significant predictors iteratively until no additional variables improve the model significantly.\n",
    "\n",
    "##### Step 1: Understanding Forward Elimination\n",
    "The Process\n",
    "\n",
    "    Start with an empty model: No independent variables (features) are included initially.\n",
    "    Iteratively add features:\n",
    "        Test each feature not in the model and evaluate its significance by fitting a new model.\n",
    "        Add the feature with the lowest p-value below the significance threshold (e.g., 0.05).\n",
    "    Stop when no features meet the inclusion criteria:\n",
    "        When adding any remaining features does not improve the model significantly, the process stops."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648f644f-de5d-49c0-9244-7f62a315e412",
   "metadata": {},
   "source": [
    "##### Step 2: Data Loading and Preprocessing\n",
    "\n",
    "Let's load the dataset and preprocess it for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7443f08a-e144-408a-bdeb-3e09fe414b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49c1103-fe7d-4dd9-b1ef-00421c2e1161",
   "metadata": {},
   "source": [
    "Handling Categorical Variables\n",
    "\n",
    "The dataset contains a categorical feature, State, which we encode using One-Hot Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "002afe3f-84e1-42e7-a686-03c892ad5a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>Profit</th>\n",
       "      <th>State_Florida</th>\n",
       "      <th>State_New York</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>192261.83</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>191792.06</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>191050.39</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>182901.99</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend     Profit  State_Florida  \\\n",
       "0  165349.20       136897.80        471784.10  192261.83          False   \n",
       "1  162597.70       151377.59        443898.53  191792.06          False   \n",
       "2  153441.51       101145.55        407934.54  191050.39           True   \n",
       "3  144372.41       118671.85        383199.62  182901.99          False   \n",
       "\n",
       "   State_New York  \n",
       "0            True  \n",
       "1           False  \n",
       "2           False  \n",
       "3            True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply One-Hot Encoding for the 'State' column\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# Check the updated dataset\n",
    "data.head(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c84acf-f68b-44f8-8046-fbda7fc65f90",
   "metadata": {},
   "source": [
    "##### Step 3: Splitting the Data\n",
    "\n",
    "Separate the dataset into independent (X) and dependent (Y) variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f04a4f0-04b8-43a2-8cca-9fe0d1494c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target variable (Y)\n",
    "X = data.drop(['Profit'], axis=1)\n",
    "Y = data['Profit']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fe568b-720d-4ed2-b942-34087c66fbbd",
   "metadata": {},
   "source": [
    "We also split the data into training and test sets for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3606e3c6-c3a9-4814-8629-0133f97951a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c5c9c2-41ae-4c46-8dc1-be95c726a70b",
   "metadata": {},
   "source": [
    "##### Step 4: Implementing Forward Elimination\n",
    "\n",
    "We implement Forward Elimination using the statsmodels library to iteratively add features to the model based on their p-values.\n",
    "##### Step 4.1: Define the Threshold for Inclusion\n",
    "\n",
    "The commonly used significance threshold is 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6db9dde0-809a-4a52-93fb-76224896cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Significance level for feature inclusion\n",
    "SL = 0.05\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7f1e77-001d-49b8-a6ea-31172face5a7",
   "metadata": {},
   "source": [
    "##### Step 4.2: Initialize Variables\n",
    "\n",
    "Start with an empty set of features and iteratively add features based on p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b26c4320-c622-496a-83dc-aea26da436de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def forward_elimination(X, Y, SL):\n",
    "    initial_features = X.columns.tolist()  # List of all features\n",
    "    selected_features = []                # List of selected features\n",
    "    \n",
    "    for i in range(len(initial_features)):\n",
    "        p_values = []\n",
    "        for feature in initial_features:\n",
    "            # Add the current feature to the model\n",
    "            temp_features = selected_features + [feature]\n",
    "            X_temp = X[temp_features]\n",
    "            X_temp = sm.add_constant(X_temp)  # Add constant for OLS\n",
    "            model = sm.OLS(Y, X_temp).fit()\n",
    "            p_values.append((feature, model.pvalues[feature]))\n",
    "        \n",
    "        # Select the feature with the smallest p-value\n",
    "        feature, p_value = min(p_values, key=lambda x: x[1])\n",
    "        \n",
    "        if p_value < SL:\n",
    "            selected_features.append(feature)\n",
    "            initial_features.remove(feature)\n",
    "        else:\n",
    "            break  # Stop if no feature meets the threshold\n",
    "    \n",
    "    return selected_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b3a58c-560a-40ae-a2bc-1f00da449b46",
   "metadata": {},
   "source": [
    "##### Step 4.3: Apply Forward Elimination\n",
    "\n",
    "Use the function to select features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16db281d-da97-4bad-8583-3225f8748c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Marketing Spend']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure all data types are float64\n",
    "X = X.astype(float)\n",
    "Y = Y.astype(float)\n",
    "\n",
    "selected_features = forward_elimination(X, Y, SL)\n",
    "selected_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1af470-a054-464e-9ab0-b64e0b1acded",
   "metadata": {},
   "source": [
    "##### Step 4.4: Train the Final Model\n",
    "\n",
    "After selecting the significant features, train the model again using only these features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e90de42-1765-40e6-8670-1fe1f38d73b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Profit</td>      <th>  R-squared:         </th> <td>   0.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.578</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   27.01</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 05 Dec 2024</td> <th>  Prob (F-statistic):</th> <td>6.07e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:34:50</td>     <th>  Log-Likelihood:    </th> <td> -196.24</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    20</td>      <th>  AIC:               </th> <td>   396.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    18</td>      <th>  BIC:               </th> <td>   398.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>           <td> 9.672e+04</td> <td> 1.76e+04</td> <td>    5.490</td> <td> 0.000</td> <td> 5.97e+04</td> <td> 1.34e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Marketing Spend</th> <td>    0.2111</td> <td>    0.041</td> <td>    5.197</td> <td> 0.000</td> <td>    0.126</td> <td>    0.296</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.559</td> <th>  Durbin-Watson:     </th> <td>   1.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.278</td> <th>  Jarque-Bera (JB):  </th> <td>   1.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.327</td> <th>  Prob(JB):          </th> <td>   0.499</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.887</td> <th>  Cond. No.          </th> <td>7.34e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 7.34e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      Profit      & \\textbf{  R-squared:         } &     0.600   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.578   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     27.01   \\\\\n",
       "\\textbf{Date:}             & Thu, 05 Dec 2024 & \\textbf{  Prob (F-statistic):} &  6.07e-05   \\\\\n",
       "\\textbf{Time:}             &     15:34:50     & \\textbf{  Log-Likelihood:    } &   -196.24   \\\\\n",
       "\\textbf{No. Observations:} &          20      & \\textbf{  AIC:               } &     396.5   \\\\\n",
       "\\textbf{Df Residuals:}     &          18      & \\textbf{  BIC:               } &     398.5   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                         & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}           &    9.672e+04  &     1.76e+04     &     5.490  &         0.000        &     5.97e+04    &     1.34e+05     \\\\\n",
       "\\textbf{Marketing Spend} &       0.2111  &        0.041     &     5.197  &         0.000        &        0.126    &        0.296     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  2.559 & \\textbf{  Durbin-Watson:     } &    1.724  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.278 & \\textbf{  Jarque-Bera (JB):  } &    1.389  \\\\\n",
       "\\textbf{Skew:}          & -0.327 & \\textbf{  Prob(JB):          } &    0.499  \\\\\n",
       "\\textbf{Kurtosis:}      &  1.887 & \\textbf{  Cond. No.          } & 7.34e+06  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 7.34e+06. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Profit   R-squared:                       0.600\n",
       "Model:                            OLS   Adj. R-squared:                  0.578\n",
       "Method:                 Least Squares   F-statistic:                     27.01\n",
       "Date:                Thu, 05 Dec 2024   Prob (F-statistic):           6.07e-05\n",
       "Time:                        15:34:50   Log-Likelihood:                -196.24\n",
       "No. Observations:                  20   AIC:                             396.5\n",
       "Df Residuals:                      18   BIC:                             398.5\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "const            9.672e+04   1.76e+04      5.490      0.000    5.97e+04    1.34e+05\n",
       "Marketing Spend     0.2111      0.041      5.197      0.000       0.126       0.296\n",
       "==============================================================================\n",
       "Omnibus:                        2.559   Durbin-Watson:                   1.724\n",
       "Prob(Omnibus):                  0.278   Jarque-Bera (JB):                1.389\n",
       "Skew:                          -0.327   Prob(JB):                        0.499\n",
       "Kurtosis:                       1.887   Cond. No.                     7.34e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.34e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the selected features\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Train the model\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_selected, Y, test_size=0.2, random_state=0)\n",
    "regressor = sm.OLS(Y_train, sm.add_constant(X_train)).fit()\n",
    "\n",
    "# Evaluate the final model\n",
    "regressor.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03cac47-f28a-472b-811b-e34051583a90",
   "metadata": {},
   "source": [
    "##### Step 5: Advanced Tools for Forward Elimination\n",
    "###### 1. Automated Feature Selection with AIC/BIC\n",
    "\n",
    "Using Akaike Information Criterion (AIC) or Bayesian Information Criterion (BIC) can provide a more robust approach to feature selection by balancing model fit and complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60692f25-728c-455c-b7e9-d3531abb0649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_elimination_aic(X, Y):\n",
    "    initial_features = X.columns.tolist()\n",
    "    selected_features = []\n",
    "    current_aic = np.inf  # Start with a very high AIC\n",
    "    \n",
    "    for i in range(len(initial_features)):\n",
    "        aic_values = []\n",
    "        for feature in initial_features:\n",
    "            # Add the feature to the model\n",
    "            temp_features = selected_features + [feature]\n",
    "            X_temp = sm.add_constant(X[temp_features])\n",
    "            model = sm.OLS(Y, X_temp).fit()\n",
    "            aic_values.append((feature, model.aic))\n",
    "        \n",
    "        # Select the feature with the lowest AIC\n",
    "        feature, aic = min(aic_values, key=lambda x: x[1])\n",
    "        \n",
    "        if aic < current_aic:\n",
    "            current_aic = aic\n",
    "            selected_features.append(feature)\n",
    "            initial_features.remove(feature)\n",
    "        else:\n",
    "            break  # Stop if no improvement in AIC\n",
    "    \n",
    "    return selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a063ca8-d657-4f89-a847-53506daf41bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Marketing Spend', 'R&D Spend']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply AIC-based feature selection\n",
    "selected_features_aic = forward_elimination_aic(X, Y)\n",
    "selected_features_aic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aeab46-21fa-4dba-b7fc-476d9d20fabc",
   "metadata": {},
   "source": [
    "###### 2. Recursive Feature Elimination (RFE)\n",
    "\n",
    "RFE works by recursively fitting the model and removing the least significant feature until the optimal set of features is found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63e9624d-730b-44e2-9a64-d96edf6bdf6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Marketing Spend', 'State_Florida', 'State_New York'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize RFE\n",
    "rfe_selector = RFE(estimator=LinearRegression(), n_features_to_select=3)\n",
    "rfe_selector.fit(X, Y)\n",
    "\n",
    "# Get selected features\n",
    "rfe_selected_features = X.columns[rfe_selector.support_]\n",
    "rfe_selected_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014fcc85-2123-4bc6-a632-68f1481b6378",
   "metadata": {},
   "source": [
    "###### 3. Lasso Regression for Automatic Feature Selection\n",
    "\n",
    "Lasso Regression (L1 regularization) can automatically shrink less important feature coefficients to zero, effectively performing feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afc61adb-ca94-473b-80b9-1259bc7672d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['R&D Spend', 'Marketing Spend'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Use Lasso for feature selection\n",
    "lasso = LassoCV(cv=5, random_state=0).fit(X, Y)\n",
    "\n",
    "# Identify selected features\n",
    "lasso_selected_features = X.columns[(lasso.coef_ != 0)]\n",
    "lasso_selected_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc5d763-4fc1-4a25-87ff-a94450d63b9c",
   "metadata": {},
   "source": [
    "##### Step 6: Evaluation of the Final Model\n",
    "\n",
    "Compare the performance of the models generated by different feature selection methods using metrics such as R-squared, MSE, or Adjusted R-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b27f4bc-3e3d-4d76-8274-26429b34e87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24093801.235591393, 0.5599364532356763)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate final model using selected features\n",
    "X_final = X[selected_features]  # Replace with your method's selected features\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_final, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "\n",
    "mse, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049c5364-3380-47e3-ba4b-6b1e0eedad64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
